{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow CNN迁移学习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "选择环境：Anaconda Python 3.5.2  \n",
    "安装Tensorflow：Python 3.5环境下运行pip install --upgrade --ignore-installed tensorflow  \n",
    "参考书籍：《TensorFlow实战Google深度学习框架（第2版）》  \n",
    "ipynb格式：点击阅读原文github"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5 卷积神经网络迁移学习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "●迁移学习：将一个问题上训练好的模型通过简单的调整使其适用于一个新的问题。  \n",
    "●可以保留训练好的Inception-v3模型中所有卷积层的参数，只替换最后一层全连接层。最后这一层全连接层之前的网络层称之为**瓶颈层（bottleneck）**。有理由认为瓶颈层输出的节点向量可以被作为任何图像的一个更加精简且表达能力更强的特征向量。于是，在新数据集上，可以直接利用这个训练好的模型进行特征提取，再将这个特征向量作为输入来训练一个新的单层全连接神经网络处理新的分类问题。  \n",
    "●一般来说，数据量足够的情况下，迁移学习的效果不如完全重新训练。但是迁移学习所需要的训练时间和训练样本都远远小于完整训练的模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 数据处理\n",
    "下载将要用到的数据（218MB）：  \n",
    "下载地址 http://download.tensorflow.org/example_images/flower_photos.tgz  \n",
    "解压后含5个子文件夹，子文件夹名称为一种花的名称，代表不同类别。平均每种花734张RGB图片，大小不相同。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 下载flower_photos数据集\n",
    "wget http://download.tensorflow.org/example_images/flower_photos.tgz\n",
    "tar xzf flower_photos.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os.path\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.platform import gfile\n",
    "\n",
    "# 原始输入数据的目录，这个目录下有5个子目录，每个子目录下保存属于该类别的所有图片\n",
    "INPUT_DATA = '/path/to/flower_photos'\n",
    "# 输出文件地址。将整理后的图片数据通过numpy的格式保存\n",
    "OUTPUT_FILE = '/path/to/flower_processed_data.npy'\n",
    "\n",
    "# 测试数据和验证数据的比例\n",
    "VALIDATION_PERCENTAGE = 10\n",
    "TEST_PERCENTAGE = 10\n",
    "\n",
    "# 测试数据并将数据分割成训练数据、验证数据和测试数据 \n",
    "def create_image_lists(sess, testing_percentage, validation_percentage):\n",
    "    sub_dirs = [x[0] for x in os.walk(INPUT_DATA)]\n",
    "    is_root_dir = True\n",
    "    \n",
    "    # 初始化各个数据集\n",
    "    training_image = []\n",
    "    training_labels = []\n",
    "    testing_image = []\n",
    "    testing_labels = []\n",
    "    validation_images = []\n",
    "    validation_labels = []\n",
    "    current_label = 0\n",
    "    \n",
    "    # 读取所有的子目录\n",
    "    for sub_dir in sub_dirs:\n",
    "        if is_root_dir:\n",
    "            is_root_dir = False\n",
    "            continue\n",
    "            \n",
    "    # 获取一个子目录中所有的图片文件\n",
    "    extensions = ['jpg','jpeg','JPG','JPEG']\n",
    "    file_list = []\n",
    "    dir_name = os.path.basename(sub_dir)\n",
    "    for extension in extensions:\n",
    "        file_glob = os.path.join(INPUT_DATA, dir_name, '*.'+ extension)\n",
    "        file_list.extend(glob.glob(file_glob))\n",
    "        if not file_list: continue\n",
    "        \n",
    "        # 处理图片数据\n",
    "        for file_name in file_list:\n",
    "            # 读取并解析图片，将图片转化为299×299以便inception-v3模型来处理\n",
    "            image_raw_data = gfile.FastGFile(file_name,'rb').read()\n",
    "            image = tf.image.decode_jpeg(image_raw_data)\n",
    "            if image.dtype != tf.float32:\n",
    "                image = tf.image.convert_image_dtype(\n",
    "                    image, dtype=tf.float32)\n",
    "            # tf.image.resize_images可以重构像素数目\n",
    "            image = tf.image.resize_images(image, [299, 299])\n",
    "            image_value = sess.run(image)\n",
    "            \n",
    "            # 随机划分数据集\n",
    "            chance = np.random.randint(100)\n",
    "            if chance < validation_percentage:\n",
    "                validation_images.append(image_value)\n",
    "                validation_labels.append(current_label)\n",
    "            elif chance < (testing_percentage + validation_percentage):\n",
    "                testing_images.append(image_value)\n",
    "                testing_labels.append(current_label)\n",
    "            else:\n",
    "                training_images.append(image_value)\n",
    "                training_labels.append(current_label)\n",
    "        current_label += 1\n",
    "        \n",
    "    # 将训练数据随机打乱以获得更好的训练效果\n",
    "    state = np.random.get_state()\n",
    "    np.random.shuffle(train_images)\n",
    "    np.random.set_state(state)\n",
    "    np.random.shuffle(training_labels)\n",
    "    \n",
    "    return np.asarray([training_images, training_labels,\n",
    "                      validation_images, validation_labels,\n",
    "                      testing_images, testing_labels])\n",
    "\n",
    "# 数据整理主函数\n",
    "def main():\n",
    "    with tf.Session() as sess:\n",
    "        processed_data = create_image_lists(\n",
    "            sess, TEST_PERCENTAGE, VALIDATION_PERCENTAGE)\n",
    "        # 通过numpy格式保存处理后的数据\n",
    "        np.save(OUTPUT_FILE, processed_data)\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面代码将所有图片数据划分成了训练、验证、测试3个数据集，且将图片从原始jpg转化为299×299×3数字矩阵。  \n",
    "下面下载谷歌提供的训练好的Inception-v3模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wget\n",
    "http://download.tensorflow.org/models/inception_v3_2016_08_28.tar.gz\n",
    "\n",
    "#解压之后可以得到训练好的模型文件inception_v3.ckpt\n",
    "tar xzf_inception_v3_2016_08_28.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "至此数据集和训练好的模型准备完毕。  \n",
    "2. 迁移学习"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os.path\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.platform import gfile\n",
    "import tensorflow.contrib.slim as slim\n",
    "\n",
    "# 加载通过TensorFlow-Slim定义好的inception_v3模型。\n",
    "import tensorflow.contrib.slim.python.slim.nets.inception_v3 as inception_v3\n",
    "\n",
    "\n",
    "# 1. 定义训练过程中将要使用到的常量。\n",
    "# 处理好之后的数据文件。\n",
    "INPUT_DATA = '../../datasets/flower_processed_data.npy'\n",
    "# 保存训练好的模型的路径。这里可以将使用新数据训练得到的模型保存下来，如果计算充足，\n",
    "# 还可以在训练完最后的全连接层之后再训练所有的网络层，使模型更贴近新数据。\n",
    "TRAIN_FILE = 'train_dir/model'\n",
    "# 谷歌提供的训练好的模型文件地址。\n",
    "CKPT_FILE = '../../datasets/inception_v3.ckpt'\n",
    "\n",
    "# 定义训练中使用的参数。\n",
    "LEARNING_RATE = 0.0001\n",
    "STEPS = 300\n",
    "BATCH = 32\n",
    "N_CLASSES = 5\n",
    "\n",
    "# 不需要从谷歌训练好的模型中加载的参数。这里就是最后的全连接层，\n",
    "# 因为在新的问题中要重新训练这一层中的参数。这里给出的是参数的前缀\n",
    "CHECKPOINT_EXCLUDE_SCOPES = 'InceptionV3/Logits,InceptionV3/AuxLogits'\n",
    "# 需要训练的网络层参数名称，在fine-tuning的过程中就是最后的全连接层。\n",
    "# 这里给出的是参数的前缀\n",
    "TRAINABLE_SCOPES = 'InceptionV3/Logits,InceptionV3/AuxLogit'\n",
    "\n",
    "\n",
    "# 2. 获取所有需要从谷歌训练好的模型中加载的参数。\n",
    "def get_tuned_variables():\n",
    "    exclusions = [scope.strip() for scope in\\\n",
    "                  CHECKPOINT_EXCLUDE_SCOPES.split(',')]\n",
    "    variables_to_restore = []\n",
    "    # 枚举inception-v3模型中所有的参数，然后判断是否需要从加载列表中移除。\n",
    "    for var in slim.get_model_variables():\n",
    "        excluded = False\n",
    "        for exclusion in exclusions:\n",
    "            if var.op.name.startswith(exclusion):\n",
    "                excluded = True\n",
    "                break\n",
    "        if not excluded:\n",
    "            variables_to_restore.append(var)\n",
    "    return variables_to_restore\n",
    "\n",
    "\n",
    "# 3. 获取所有需要训练的变量列表。\n",
    "def get_trainable_variables():    \n",
    "    scopes = [scope.strip() for scope in TRAINABLE_SCOPES.split(',')]\n",
    "    variables_to_train = []\n",
    "    # 枚举所有需要训练的参数前缀，并通过这些前缀找到所有需要训练的参数。\n",
    "    for scope in scopes:\n",
    "        variables = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope)\n",
    "        variables_to_train.extend(variables)\n",
    "    return variables_to_train\n",
    "\n",
    "\n",
    "# 4. 定义训练过程\n",
    "def main():\n",
    "    # 加载预处理好的数据。\n",
    "    processed_data = np.load(INPUT_DATA)\n",
    "    training_images = processed_data[0]\n",
    "    n_training_example = len(training_images)\n",
    "    training_labels = processed_data[1]\n",
    "    \n",
    "    validation_images = processed_data[2]\n",
    "    validation_labels = processed_data[3]\n",
    "    \n",
    "    testing_images = processed_data[4]\n",
    "    testing_labels = processed_data[5]\n",
    "    print(\"%d training examples, %d validation examples and %d testing examples.\" % (\n",
    "        n_training_example, len(validation_labels), len(testing_labels)))\n",
    "\n",
    "    # 1. 定义inception-v3的输入输出\n",
    "    images = tf.placeholder(tf.float32, [None, 299, 299, 3], name='input_images')\n",
    "    labels = tf.placeholder(tf.int64, [None], name='labels')\n",
    "    \n",
    "    # 2. 定义前向传播、损失函数、反向传播\n",
    "    # 定义inception-v3模型。因为谷歌给出的只有模型参数取值，所以这里\n",
    "    # 需要在这个代码中定义inception-v3的模型结构。虽然理论上需要区分训练和\n",
    "    # 测试中使用到的模型，也就是说在测试时应该使用is_training=False，但是\n",
    "    # 因为预先训练好的inception-v3模型中使用的batch normalization参数与\n",
    "    # 新的数据会有出入，所以这里直接使用同一个模型来做测试。\n",
    "    with slim.arg_scope(inception_v3.inception_v3_arg_scope()):\n",
    "        logits, _ = inception_v3.inception_v3(\n",
    "            images, num_classes=N_CLASSES, is_training=True)\n",
    "    \n",
    "    # 定义损失函数\n",
    "    trainable_variables = get_trainable_variables()    # 自定义函数，获取需要训练的变量\n",
    "    tf.losses.softmax_cross_entropy(\n",
    "        tf.one_hot(labels, N_CLASSES), logits, weights=1.0)\n",
    "    total_loss = tf.losses.get_total_loss()\n",
    "    \n",
    "    # 定义反向传播\n",
    "    train_step = tf.train.RMSPropOptimizer(LEARNING_RATE).minimize(total_loss)\n",
    "    \n",
    "    # 计算正确率。\n",
    "    with tf.name_scope('evaluation'):\n",
    "        correct_prediction = tf.equal(tf.argmax(logits, 1), labels)\n",
    "        evaluation_step = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "                \n",
    "    # 定义加载Google训练好的Inception-v3模型的Saver。\n",
    "    load_fn = slim.assign_from_checkpoint_fn(\n",
    "      CKPT_FILE,\n",
    "      get_tuned_variables(),                          # 自定义函数，获取需要加载的参数\n",
    "      ignore_missing_vars=True)\n",
    "    \n",
    "    # 3. 建立会话，训练模型\n",
    "    saver = tf.train.Saver()      # 定义保存新模型的Saver。\n",
    "    with tf.Session() as sess:\n",
    "        # 初始化没有加载进来的变量。注意这个过程要在加载模型之前，\n",
    "        # 否则初始化过程会将已经加载好的变量重新赋值。\n",
    "        init = tf.global_variables_initializer()\n",
    "        sess.run(init)\n",
    "        \n",
    "        # 加载谷歌已经训练好的模型。\n",
    "        print('Loading tuned variables from %s' % CKPT_FILE)\n",
    "        load_fn(sess)\n",
    "            \n",
    "        start = 0\n",
    "        end = BATCH\n",
    "        for i in range(STEPS):\n",
    "            # 运行训练过程，这里不会更新全部参数，只会更新指定部分的参数\n",
    "            _, loss = sess.run([train_step, total_loss], feed_dict={\n",
    "                images: training_images[start:end], \n",
    "                labels: training_labels[start:end]})\n",
    "\n",
    "            # 保存并输出日志\n",
    "            if i % 30 == 0 or i + 1 == STEPS:\n",
    "                saver.save(sess, TRAIN_FILE, global_step=i)\n",
    "                validation_accuracy = sess.run(evaluation_step, feed_dict={\n",
    "                    images: validation_images, labels: validation_labels})\n",
    "                print('Step %d: Training loss is %.1f Validation accuracy = %.1f%%' % (\n",
    "                    i, loss, validation_accuracy * 100.0))\n",
    "                         \n",
    "            # 获取下一个batch\n",
    "            start = end\n",
    "            if start == n_training_example:\n",
    "                start = 0\n",
    "            end = start + BATCH\n",
    "            if end > n_training_example:\n",
    "                end = n_training_example\n",
    "            \n",
    "        # 在最后的测试数据上测试正确率。\n",
    "        test_accuracy = sess.run(evaluation_step, feed_dict={\n",
    "            images: testing_images, labels: testing_labels})\n",
    "        print('Final test accuracy = %.1f%%' % (test_accuracy * 100))\n",
    "        \n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final test accuracy 约为 91.9% ，可以看到模型在新的数据集上很快能够收敛，并达到不错的分类效果。  \n",
    "通过这种特殊结构的神经网络，可以将图像识别问题的准确率提高到一个新的层次。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
