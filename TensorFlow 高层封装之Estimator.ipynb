{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow 高层封装之Estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "选择环境：Anaconda Python 3.6.6  \n",
    "安装Tensorflow：Python 3.6环境下运行pip install --upgrade --ignore-installed tensorflow  \n",
    "参考书籍：《TensorFlow实战Google深度学习框架（第2版）》  \n",
    "ipynb格式：点击阅读原文github"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.3 Estimator介绍\n",
    "\n",
    "除了第三方提供的TensorFlow高层封装API，还推出了官方支持的高层封装——`tf.estimator`。因为Estimator是TensorFlow官方提供的高层API，所以它更好地整合了原生态TensorFlow提供的功能。\n",
    "\n",
    "#### Estimator基本用法\n",
    "\n",
    "在MNIST数据集上，通过Estimator实现全连接神经网络的代码："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-24T03:42:27.829663Z",
     "start_time": "2018-12-24T03:40:48.195074Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-f43a667cece7>:8: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Users\\74575\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Users\\74575\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ../../datasets/MNIST_data\\train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\74575\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ../../datasets/MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting ../../datasets/MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting ../../datasets/MNIST_data\\t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\74575\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'log', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000018CBE9DF860>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "WARNING:tensorflow:From C:\\Users\\74575\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\estimator\\inputs\\queues\\feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From C:\\Users\\74575\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\estimator\\inputs\\queues\\feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "WARNING:tensorflow:From C:\\Users\\74575\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py:804: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into log\\model.ckpt.\n",
      "INFO:tensorflow:loss = 294.19247, step = 1\n",
      "INFO:tensorflow:global_step/sec: 113.971\n",
      "INFO:tensorflow:loss = 31.96075, step = 101 (0.879 sec)\n",
      "INFO:tensorflow:global_step/sec: 123.037\n",
      "INFO:tensorflow:loss = 38.02909, step = 201 (0.813 sec)\n",
      "INFO:tensorflow:global_step/sec: 131.822\n",
      "INFO:tensorflow:loss = 20.294195, step = 301 (0.758 sec)\n",
      "INFO:tensorflow:global_step/sec: 129.111\n",
      "INFO:tensorflow:loss = 21.457481, step = 401 (0.775 sec)\n",
      "INFO:tensorflow:global_step/sec: 125.843\n",
      "INFO:tensorflow:loss = 14.445357, step = 501 (0.795 sec)\n",
      "INFO:tensorflow:global_step/sec: 125.827\n",
      "INFO:tensorflow:loss = 11.384664, step = 601 (0.795 sec)\n",
      "INFO:tensorflow:global_step/sec: 131.567\n",
      "INFO:tensorflow:loss = 29.407856, step = 701 (0.760 sec)\n",
      "INFO:tensorflow:global_step/sec: 133.774\n",
      "INFO:tensorflow:loss = 9.068907, step = 801 (0.748 sec)\n",
      "INFO:tensorflow:global_step/sec: 131.253\n",
      "INFO:tensorflow:loss = 10.547297, step = 901 (0.761 sec)\n",
      "INFO:tensorflow:global_step/sec: 129.624\n",
      "INFO:tensorflow:loss = 9.021421, step = 1001 (0.772 sec)\n",
      "INFO:tensorflow:global_step/sec: 134.884\n",
      "INFO:tensorflow:loss = 12.484009, step = 1101 (0.741 sec)\n",
      "INFO:tensorflow:global_step/sec: 131.102\n",
      "INFO:tensorflow:loss = 6.4881473, step = 1201 (0.763 sec)\n",
      "INFO:tensorflow:global_step/sec: 125.776\n",
      "INFO:tensorflow:loss = 6.9853973, step = 1301 (0.795 sec)\n",
      "INFO:tensorflow:global_step/sec: 132.696\n",
      "INFO:tensorflow:loss = 4.297453, step = 1401 (0.754 sec)\n",
      "INFO:tensorflow:global_step/sec: 125.155\n",
      "INFO:tensorflow:loss = 4.050256, step = 1501 (0.799 sec)\n",
      "INFO:tensorflow:global_step/sec: 135.31\n",
      "INFO:tensorflow:loss = 9.130176, step = 1601 (0.739 sec)\n",
      "INFO:tensorflow:global_step/sec: 118.314\n",
      "INFO:tensorflow:loss = 12.767822, step = 1701 (0.845 sec)\n",
      "INFO:tensorflow:global_step/sec: 133.638\n",
      "INFO:tensorflow:loss = 2.8617094, step = 1801 (0.748 sec)\n",
      "INFO:tensorflow:global_step/sec: 127.794\n",
      "INFO:tensorflow:loss = 1.628505, step = 1901 (0.783 sec)\n",
      "INFO:tensorflow:global_step/sec: 128.349\n",
      "INFO:tensorflow:loss = 2.1086955, step = 2001 (0.779 sec)\n",
      "INFO:tensorflow:global_step/sec: 126.756\n",
      "INFO:tensorflow:loss = 5.149807, step = 2101 (0.790 sec)\n",
      "INFO:tensorflow:global_step/sec: 128.014\n",
      "INFO:tensorflow:loss = 3.912758, step = 2201 (0.780 sec)\n",
      "INFO:tensorflow:global_step/sec: 105.833\n",
      "INFO:tensorflow:loss = 3.5834014, step = 2301 (0.952 sec)\n",
      "INFO:tensorflow:global_step/sec: 107.51\n",
      "INFO:tensorflow:loss = 3.5894692, step = 2401 (0.923 sec)\n",
      "INFO:tensorflow:global_step/sec: 99.2601\n",
      "INFO:tensorflow:loss = 0.996752, step = 2501 (1.007 sec)\n",
      "INFO:tensorflow:global_step/sec: 125.634\n",
      "INFO:tensorflow:loss = 2.292041, step = 2601 (0.796 sec)\n",
      "INFO:tensorflow:global_step/sec: 104.494\n",
      "INFO:tensorflow:loss = 1.9610035, step = 2701 (0.958 sec)\n",
      "INFO:tensorflow:global_step/sec: 110.123\n",
      "INFO:tensorflow:loss = 8.000964, step = 2801 (0.914 sec)\n",
      "INFO:tensorflow:global_step/sec: 113.926\n",
      "INFO:tensorflow:loss = 1.7568606, step = 2901 (0.871 sec)\n",
      "INFO:tensorflow:global_step/sec: 131.445\n",
      "INFO:tensorflow:loss = 2.9246392, step = 3001 (0.760 sec)\n",
      "INFO:tensorflow:global_step/sec: 135.354\n",
      "INFO:tensorflow:loss = 0.98687476, step = 3101 (0.740 sec)\n",
      "INFO:tensorflow:global_step/sec: 123.572\n",
      "INFO:tensorflow:loss = 1.6999768, step = 3201 (0.809 sec)\n",
      "INFO:tensorflow:global_step/sec: 132.279\n",
      "INFO:tensorflow:loss = 1.0643435, step = 3301 (0.756 sec)\n",
      "INFO:tensorflow:global_step/sec: 114.04\n",
      "INFO:tensorflow:loss = 4.944416, step = 3401 (0.879 sec)\n",
      "INFO:tensorflow:global_step/sec: 98.7404\n",
      "INFO:tensorflow:loss = 2.6892908, step = 3501 (1.012 sec)\n",
      "INFO:tensorflow:global_step/sec: 132.089\n",
      "INFO:tensorflow:loss = 1.2348325, step = 3601 (0.756 sec)\n",
      "INFO:tensorflow:global_step/sec: 132.015\n",
      "INFO:tensorflow:loss = 0.5584644, step = 3701 (0.756 sec)\n",
      "INFO:tensorflow:global_step/sec: 119.174\n",
      "INFO:tensorflow:loss = 1.4924281, step = 3801 (0.842 sec)\n",
      "INFO:tensorflow:global_step/sec: 96.6351\n",
      "INFO:tensorflow:loss = 0.5310763, step = 3901 (1.033 sec)\n",
      "INFO:tensorflow:global_step/sec: 121.249\n",
      "INFO:tensorflow:loss = 0.71055865, step = 4001 (0.824 sec)\n",
      "INFO:tensorflow:global_step/sec: 130.328\n",
      "INFO:tensorflow:loss = 0.9254358, step = 4101 (0.767 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 133.923\n",
      "INFO:tensorflow:loss = 0.6870288, step = 4201 (0.747 sec)\n",
      "INFO:tensorflow:global_step/sec: 138.635\n",
      "INFO:tensorflow:loss = 0.5232655, step = 4301 (0.722 sec)\n",
      "INFO:tensorflow:global_step/sec: 136.262\n",
      "INFO:tensorflow:loss = 3.275207, step = 4401 (0.733 sec)\n",
      "INFO:tensorflow:global_step/sec: 134.95\n",
      "INFO:tensorflow:loss = 0.50241625, step = 4501 (0.741 sec)\n",
      "INFO:tensorflow:global_step/sec: 138.39\n",
      "INFO:tensorflow:loss = 0.7609047, step = 4601 (0.723 sec)\n",
      "INFO:tensorflow:global_step/sec: 125.66\n",
      "INFO:tensorflow:loss = 0.5214219, step = 4701 (0.797 sec)\n",
      "INFO:tensorflow:global_step/sec: 112.446\n",
      "INFO:tensorflow:loss = 0.22302903, step = 4801 (0.890 sec)\n",
      "INFO:tensorflow:global_step/sec: 99.952\n",
      "INFO:tensorflow:loss = 0.08129305, step = 4901 (1.005 sec)\n",
      "INFO:tensorflow:global_step/sec: 122.789\n",
      "INFO:tensorflow:loss = 0.38298243, step = 5001 (0.810 sec)\n",
      "INFO:tensorflow:global_step/sec: 97.7777\n",
      "INFO:tensorflow:loss = 0.51912725, step = 5101 (1.021 sec)\n",
      "INFO:tensorflow:global_step/sec: 107.936\n",
      "INFO:tensorflow:loss = 1.6481347, step = 5201 (0.936 sec)\n",
      "INFO:tensorflow:global_step/sec: 128.228\n",
      "INFO:tensorflow:loss = 0.1451002, step = 5301 (0.771 sec)\n",
      "INFO:tensorflow:global_step/sec: 128.594\n",
      "INFO:tensorflow:loss = 1.0420446, step = 5401 (0.778 sec)\n",
      "INFO:tensorflow:global_step/sec: 135.885\n",
      "INFO:tensorflow:loss = 0.872427, step = 5501 (0.736 sec)\n",
      "INFO:tensorflow:global_step/sec: 134.096\n",
      "INFO:tensorflow:loss = 0.31607276, step = 5601 (0.746 sec)\n",
      "INFO:tensorflow:global_step/sec: 130.802\n",
      "INFO:tensorflow:loss = 2.5355606, step = 5701 (0.764 sec)\n",
      "INFO:tensorflow:global_step/sec: 120.92\n",
      "INFO:tensorflow:loss = 1.1654328, step = 5801 (0.828 sec)\n",
      "INFO:tensorflow:global_step/sec: 118.716\n",
      "INFO:tensorflow:loss = 1.8348554, step = 5901 (0.842 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.628\n",
      "INFO:tensorflow:loss = 0.2639963, step = 6001 (0.974 sec)\n",
      "INFO:tensorflow:global_step/sec: 116.546\n",
      "INFO:tensorflow:loss = 1.6890692, step = 6101 (0.858 sec)\n",
      "INFO:tensorflow:global_step/sec: 123.515\n",
      "INFO:tensorflow:loss = 1.6361301, step = 6201 (0.810 sec)\n",
      "INFO:tensorflow:global_step/sec: 137.485\n",
      "INFO:tensorflow:loss = 0.5457367, step = 6301 (0.726 sec)\n",
      "INFO:tensorflow:global_step/sec: 133.036\n",
      "INFO:tensorflow:loss = 1.158796, step = 6401 (0.753 sec)\n",
      "INFO:tensorflow:global_step/sec: 130.874\n",
      "INFO:tensorflow:loss = 0.021179369, step = 6501 (0.764 sec)\n",
      "INFO:tensorflow:global_step/sec: 132.785\n",
      "INFO:tensorflow:loss = 1.1079682, step = 6601 (0.753 sec)\n",
      "INFO:tensorflow:global_step/sec: 132.718\n",
      "INFO:tensorflow:loss = 0.20272732, step = 6701 (0.752 sec)\n",
      "INFO:tensorflow:global_step/sec: 132.66\n",
      "INFO:tensorflow:loss = 0.32532, step = 6801 (0.755 sec)\n",
      "INFO:tensorflow:global_step/sec: 135.131\n",
      "INFO:tensorflow:loss = 0.19151448, step = 6901 (0.740 sec)\n",
      "INFO:tensorflow:global_step/sec: 136.173\n",
      "INFO:tensorflow:loss = 0.47957045, step = 7001 (0.733 sec)\n",
      "INFO:tensorflow:global_step/sec: 134.646\n",
      "INFO:tensorflow:loss = 0.8512699, step = 7101 (0.743 sec)\n",
      "INFO:tensorflow:global_step/sec: 138.856\n",
      "INFO:tensorflow:loss = 1.0256495, step = 7201 (0.721 sec)\n",
      "INFO:tensorflow:global_step/sec: 137.916\n",
      "INFO:tensorflow:loss = 0.38061184, step = 7301 (0.725 sec)\n",
      "INFO:tensorflow:global_step/sec: 128.35\n",
      "INFO:tensorflow:loss = 0.3417338, step = 7401 (0.778 sec)\n",
      "INFO:tensorflow:global_step/sec: 134.312\n",
      "INFO:tensorflow:loss = 0.36859465, step = 7501 (0.746 sec)\n",
      "INFO:tensorflow:global_step/sec: 136.68\n",
      "INFO:tensorflow:loss = 0.293447, step = 7601 (0.732 sec)\n",
      "INFO:tensorflow:global_step/sec: 134.579\n",
      "INFO:tensorflow:loss = 0.238654, step = 7701 (0.743 sec)\n",
      "INFO:tensorflow:global_step/sec: 134.098\n",
      "INFO:tensorflow:loss = 0.031743374, step = 7801 (0.746 sec)\n",
      "INFO:tensorflow:global_step/sec: 139.674\n",
      "INFO:tensorflow:loss = 0.39482903, step = 7901 (0.716 sec)\n",
      "INFO:tensorflow:global_step/sec: 134.986\n",
      "INFO:tensorflow:loss = 0.27520216, step = 8001 (0.741 sec)\n",
      "INFO:tensorflow:global_step/sec: 133.772\n",
      "INFO:tensorflow:loss = 0.47083062, step = 8101 (0.748 sec)\n",
      "INFO:tensorflow:global_step/sec: 137.374\n",
      "INFO:tensorflow:loss = 2.0758991, step = 8201 (0.728 sec)\n",
      "INFO:tensorflow:global_step/sec: 135.94\n",
      "INFO:tensorflow:loss = 1.2536056, step = 8301 (0.736 sec)\n",
      "INFO:tensorflow:global_step/sec: 136.287\n",
      "INFO:tensorflow:loss = 0.041521538, step = 8401 (0.734 sec)\n",
      "INFO:tensorflow:global_step/sec: 135.496\n",
      "INFO:tensorflow:loss = 0.046252687, step = 8501 (0.738 sec)\n",
      "INFO:tensorflow:global_step/sec: 136.106\n",
      "INFO:tensorflow:loss = 0.11684248, step = 8601 (0.734 sec)\n",
      "INFO:tensorflow:global_step/sec: 134.584\n",
      "INFO:tensorflow:loss = 0.042143453, step = 8701 (0.743 sec)\n",
      "INFO:tensorflow:global_step/sec: 133.737\n",
      "INFO:tensorflow:loss = 0.07859042, step = 8801 (0.749 sec)\n",
      "INFO:tensorflow:global_step/sec: 134.183\n",
      "INFO:tensorflow:loss = 0.028375529, step = 8901 (0.744 sec)\n",
      "INFO:tensorflow:global_step/sec: 132.702\n",
      "INFO:tensorflow:loss = 1.2176268, step = 9001 (0.755 sec)\n",
      "INFO:tensorflow:global_step/sec: 132.655\n",
      "INFO:tensorflow:loss = 0.10700803, step = 9101 (0.754 sec)\n",
      "INFO:tensorflow:global_step/sec: 135.101\n",
      "INFO:tensorflow:loss = 0.012086301, step = 9201 (0.740 sec)\n",
      "INFO:tensorflow:global_step/sec: 132.837\n",
      "INFO:tensorflow:loss = 0.10237409, step = 9301 (0.752 sec)\n",
      "INFO:tensorflow:global_step/sec: 133.976\n",
      "INFO:tensorflow:loss = 0.044098586, step = 9401 (0.747 sec)\n",
      "INFO:tensorflow:global_step/sec: 138.362\n",
      "INFO:tensorflow:loss = 0.012265393, step = 9501 (0.723 sec)\n",
      "INFO:tensorflow:global_step/sec: 132.613\n",
      "INFO:tensorflow:loss = 0.038655758, step = 9601 (0.753 sec)\n",
      "INFO:tensorflow:global_step/sec: 137.205\n",
      "INFO:tensorflow:loss = 0.030967256, step = 9701 (0.729 sec)\n",
      "INFO:tensorflow:global_step/sec: 135.217\n",
      "INFO:tensorflow:loss = 0.029511414, step = 9801 (0.741 sec)\n",
      "INFO:tensorflow:global_step/sec: 137.435\n",
      "INFO:tensorflow:loss = 0.0031722882, step = 9901 (0.727 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 10000 into log\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.045251183.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-12-24-03:42:27\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from log\\model.ckpt-10000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-12-24-03:42:27\n",
      "INFO:tensorflow:Saving dict for global step 10000: accuracy = 0.9817, average_loss = 0.08125357, global_step = 10000, loss = 10.285262\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 10000: log\\model.ckpt-10000\n",
      "\n",
      "test_results:  {'accuracy': 0.9817, 'average_loss': 0.08125357, 'loss': 10.285262, 'global_step': 10000}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "# 1. 模型定义\n",
    "# 将TensorFlow日志信息输出到屏幕\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "mnist = input_data.read_data_sets(\"../../datasets/MNIST_data\", one_hot=False)\n",
    "\n",
    "# 指定神经网络的输入层。这里所有指定的输入层都会拼接在一起作为整个神经网络的输入\n",
    "feature_columns = [tf.feature_column.numeric_column(\"image\", shape=[784])]\n",
    "\n",
    "# 通过TensorFlow提供的封装好的Estimator定义神经网络模型。\n",
    "#   feature_columns参数给出了神经网络输入层需要用到的数据；\n",
    "#   hidden_units参数给出了神经网络的结构（注意这DNNClassifier只能定义多层全连接层\n",
    "#               神经网络，而hidden_units列表中给出了每一层隐藏层的节点个数）；\n",
    "#   n_classes参数给出了总共类目的数量；\n",
    "#   optimizer参数给出了使用的优化函数；\n",
    "#   model_dir参数给出了训练过程中的loss及其他指标的保存地址，可使用TensorBoard可视化\n",
    "estimator = tf.estimator.DNNClassifier(feature_columns=feature_columns,\n",
    "                                       hidden_units=[500],\n",
    "                                       n_classes=10,\n",
    "                                       optimizer=tf.train.AdamOptimizer(),\n",
    "                                       model_dir=\"log\")\n",
    "\n",
    "\n",
    "# 2. 训练模型\n",
    "# 先定义输入数据：\n",
    "#   x:如果上面feature_columns中指定了多个，那么这里需要对每一个对应提供数据\n",
    "#   y:需要提供每一个x对应的正确答案，这里要求分类的结果是一个正数\n",
    "#   num_epochs:指定数据循环轮数，测试时为1\n",
    "#   batch_size:指定一个batch大小\n",
    "#   shuffle:指定是否需要对数据进行随机打乱\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "      x={\"image\": mnist.train.images},\n",
    "      y=mnist.train.labels.astype(np.int32),\n",
    "      num_epochs=None,\n",
    "      batch_size=128,\n",
    "      shuffle=True)\n",
    "\n",
    "# 注意这里没有指定损失函数，通过DNNClassifier定义的模型会使用交叉熵作为损失函数\n",
    "estimator.train(input_fn=train_input_fn, steps=10000)\n",
    "\n",
    "\n",
    "# 3. 测试模型\n",
    "# 定义测试时的数据输入，和训练时的数据输入基本一致\n",
    "test_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "      x={\"image\": mnist.test.images},\n",
    "      y=mnist.test.labels.astype(np.int32),\n",
    "      num_epochs=1,\n",
    "      batch_size=128,\n",
    "      shuffle=False)\n",
    "\n",
    "test_results = estimator.evaluate(input_fn=test_input_fn)\n",
    "print('\\ntest_results: ',test_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看出，使用预先定义好的**Estimator可以更加深层次地封装神经网络的定义和训练过程。用户只需要关注模型的输入以及模型的结构，其他的工作都可以通过Estimator自动完成。**\n",
    "\n",
    "#### Estimator自定义模型\n",
    "\n",
    "预先定义好的Estimator功能有限，比如：\n",
    "- 不能灵活选择模型的结构，如卷积神经网络或者循环神经网络；\n",
    "- 没有办法支持自定义的损失函数；\n",
    "- 每一层使用的激活函数也是自定义好的。\n",
    "\n",
    "所以需要使用Estimator自定义模型。下面代码展示了如何通过自定义的方式使用CNN解决MNIST问题："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-24T05:20:36.129927Z",
     "start_time": "2018-12-24T05:20:32.399387Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "# 通过tf.layers来定义模型结构。这里可以使用原生态TensorFlow API或者任何TensorFlow\n",
    "# 的高层封装。x给出了输入层张量，is_training指明了是否为训练。该函数返回前向传播的结果。\n",
    "def lenet(x, is_training):\n",
    "    x = tf.reshape(x, shape=[-1, 28, 28, 1])\n",
    "    conv1 = tf.layers.conv2d(x, 32, 5, activation=tf.nn.relu)\n",
    "    conv1 = tf.layers.max_pooling2d(conv1, 2, 2)\n",
    "    conv2 = tf.layers.conv2d(conv1, 64, 3, activation=tf.nn.relu)\n",
    "    conv2 = tf.layers.max_pooling2d(conv2, 2, 2)\n",
    "    fc1 = tf.contrib.layers.flatten(conv2)\n",
    "    fc1 = tf.layers.dense(fc1, 1024)\n",
    "    fc1 = tf.layers.dropout(fc1, rate=0.4, training=is_training)\n",
    "    return tf.layers.dense(fc1, 10)\n",
    "\n",
    "\n",
    "# 自定义Estimator中使用的模型。定义的函数有4 个输入：\n",
    "#    features给出了在输入函数中会提供的输入层张量。注意这是一个字典，字典里的内容是\n",
    "#       通过tf.estimator.inputs.numpy_input_fn中x参数的内容指定的。\n",
    "#    labels是正确答案，这个字段的内容是通过numpy_input_fn 中y参数给出的。\n",
    "#    mode 的取值有3 种可能，分别对应Estimator类的train 、evaluate和predict这3 个函数。\n",
    "#       通过这个参数可以判断当前是有是训练过程。\n",
    "#    params是一个字典，这个字典中可以给出模型相关的任何超参数。比如这里的学习率。\n",
    "def model_fn(features, labels, mode, params):\n",
    "    # 定义神经网络的结构并通过输入得到前向传播的结果\n",
    "    predict = lenet(\n",
    "        features[\"image\"], mode == tf.estimator.ModeKeys.TRAIN)\n",
    "\n",
    "    # 如果在预测模式，那么只需要将前向传播结果返回\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "            mode=mode,\n",
    "            predictions={\"result\": tf.argmax(predict, 1)})\n",
    "\n",
    "    # 定义损失函数\n",
    "    loss = tf.reduce_mean(\n",
    "        tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "           logits=predict, labels=labels))\n",
    "\n",
    "    # 定义优化函数\n",
    "    optimizer = tf.train.GradientDescentOptimizer(\n",
    "        learning_rate=params[\"learning_rate\"])\n",
    "\n",
    "    # 定义训练过程\n",
    "    train_op = optimizer.minimize(\n",
    "        loss=loss, global_step=tf.train.get_global_step())\n",
    "\n",
    "    # 定义评价标准\n",
    "    eval_metric_ops = {\n",
    "        \"accuracy\": tf.metrics.accuracy(\n",
    "            tf.argmax(predict, 1), labels)\n",
    "    }\n",
    "\n",
    "    # 返回模型训练过程需要使用的损失函数、训练过程和评测方法\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "        mode=mode,\n",
    "        loss=loss,\n",
    "        train_op=train_op,\n",
    "        eval_metric_ops=eval_metric_ops)\n",
    "\n",
    "\n",
    "# 建立Estimator\n",
    "model_params = {\"learning_rate\": 0.01}\n",
    "estimator = tf.estimator.Estimator(model_fn=model_fn, \n",
    "                                   params=model_params,\n",
    "                                   model_dir='log')\n",
    "\n",
    "# 加载数据\n",
    "mnist = input_data.read_data_sets(\"../../datasets/MNIST_data\", one_hot=False)\n",
    "\n",
    "# 训练\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "      x={\"image\": mnist.train.images},\n",
    "      y=mnist.train.labels.astype(np.int32),\n",
    "      num_epochs=None,\n",
    "      batch_size=128,\n",
    "      shuffle=True)\n",
    "\n",
    "estimator.train(input_fn=train_input_fn, steps=10000)\n",
    "\n",
    "# 测试\n",
    "test_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "      x={\"image\": mnist.test.images},\n",
    "      y=mnist.test.labels.astype(np.int32),\n",
    "      num_epochs=1,\n",
    "      batch_size=128,\n",
    "      shuffle=False)\n",
    "\n",
    "test_results = estimator.evaluate(input_fn=test_input_fn)\n",
    "print(\"\\ntest_results: \", test_results, '\\n')\n",
    "\n",
    "# 预测\n",
    "predict_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "      x={\"image\": mnist.test.images[:10]},\n",
    "      num_epochs=1,\n",
    "      shuffle=False)\n",
    "\n",
    "predictions = estimator.predict(input_fn=predict_input_fn)\n",
    "for i, p in enumerate(predictions):\n",
    "    plt.imshow(mnist.test.images[i].reshape([28, 28]))\n",
    "    plt.show()\n",
    "    print(\"Prediction %s\" % p[\"result\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看出，Estimator能非常好地支持自定义模型，而且模型结构的定义过程中也可以使用其他的TensorFlow高层封装（比如代码中使用到的tf.layers）。Estimator在支持自定义模型结构的同时，并不影响它对训练过程的封装。\n",
    "\n",
    "#### 使用数据集（datasets）作为Estimator输入\n",
    "\n",
    "这里将使用iris分类数据集(http://archive.ics.uci.edu/ml/datasets/Iris) 。iris数据集需要通过4个特征来分辨3种类型的植物。iris 数据集中总共包含了150个样本，其中包括120条训练数据、30条测试数据。这些数据都存储在csv文件中。下面介绍了如何通过Estimator 和数据集相结合的方式完成整个数据读取和模型训练的过程："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-24T05:39:19.862Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\74575\\AppData\\Local\\Temp\\tmp62ysk1vd\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\74575\\\\AppData\\\\Local\\\\Temp\\\\tmp62ysk1vd', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000025151C17780>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into C:\\Users\\74575\\AppData\\Local\\Temp\\tmp62ysk1vd\\model.ckpt.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "# Estimator的自定义输入函数需要每一次被调用时可以得到一个batch的数据（包括所有的\n",
    "# 输入层数据和期待的正确答案标注），通过数据集可以很自然地实现这个过程。虽然Estimator\n",
    "# 要求的自定义输入函数不能有参数，但是通过pythoy提供的lambda表达式可以快速将下面的\n",
    "# 函数转化为不带参数的函数。\n",
    "def my_input_fn(file_path, perform_shuffle=False, repeat_count=1):\n",
    "    # 解析csv文件中一行\n",
    "    def decode_csv(line):\n",
    "        parsed_line = tf.decode_csv(line, [[0.], [0.], [0.], [0.], [0]])\n",
    "        # Estimator的输入函数要求特征是一个字典，所以这里返回的也需要是一个字典。\n",
    "        # 字典中key的定义需要和DNNClassifier中feature_columns的定义匹配：x。\n",
    "        return {\"x\": parsed_line[:-1]}, parsed_line[-1:]\n",
    "\n",
    "    # 使用数据集输入数据。具体使用方法参考第7章。\n",
    "    dataset = tf.data.TextLineDataset(file_path).skip(1).map(decode_csv)\n",
    "    if perform_shuffle:\n",
    "        dataset = dataset.shuffle(buffer_size=256)\n",
    "    dataset = dataset.repeat(repeat_count) \n",
    "    dataset = dataset.batch(32) \n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    # 通过定义的数据集得到一个batch的输入数据。这个就是整个自定义的输入过程的返回结果\n",
    "    batch_features, batch_labels = iterator.get_next()\n",
    "    return batch_features, batch_labels\n",
    "\n",
    "# 与10.3.1小节中类似地定义Estimator\n",
    "feature_columns = [tf.feature_column.numeric_column(\"x\", shape=[4])]\n",
    "classifier = tf.estimator.DNNClassifier(\n",
    "    feature_columns=feature_columns,  \n",
    "    hidden_units=[10, 10],  \n",
    "    n_classes=3)\n",
    "\n",
    "# 使用lambda表达式将训练的相关信息传入自定义输入数据处理函数，并生成需要的输入函数\n",
    "classifier.train(\n",
    "    input_fn=lambda: my_input_fn(\"../../datasets/iris_training.csv\", True, 100))\n",
    "\n",
    "# 对于测试，同样使用lambda，这样可以大大减少冗余代码\n",
    "test_results = classifier.evaluate(\n",
    "    input_fn=lambda: my_input_fn(\"../../datasets/iris_test.csv\", False, 1))\n",
    "print(\"\\nTest accuracy: %g %%\" % (test_results[\"accuracy\"]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看出Estimator可以非常好地和数据集结合，这样就能够很容易地支持海量数据读入或者复杂的数据预处理流程。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "290.417px",
    "left": "757.273px",
    "right": "20px",
    "top": "120px",
    "width": "357.784px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
