{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow单隐层网络实现手写数字识别"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "选择环境：Anaconda Python 3.5.2  \n",
    "安装Tensorflow：Python 3.5环境下运行pip install --upgrade --ignore-installed tensorflow  \n",
    "参考书籍：《TensorFlow实战Google深度学习框架（第2版）》  \n",
    "ipynb格式：点击阅读原文github"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 MNIST数据处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST数据集是NIST数据集的一个子集，包含60000张图片作为训练数据，10000张图片作为测试数据，每一张图片代表0-9中的一个数字，图片大小28×28。  \n",
    "在Yann LeCun教授的网站（http://yann.lecun.com/exdb/mnist ）中对MNIST数据集做了详细的介绍。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /path/to/MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting /path/to/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting /path/to/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /path/to/MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "Training data size:  55000\n",
      "Validating data size:  5000\n",
      "Testing data size:  10000\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "# 载入MNIST数据集\n",
    "mnist=input_data.read_data_sets(\"/path/to/MNIST_data/\",one_hot=True)\n",
    "print(\"Training data size: \", mnist.train.num_examples)\n",
    "print(\"Validating data size: \", mnist.validation.num_examples)\n",
    "print(\"Testing data size: \", mnist.test.num_examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " input_data.read_data_sets函数生成的类会自动将数据集划分为3个子集：train、validation和test。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example training data:  [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.3803922  0.37647063 0.3019608\n",
      " 0.46274513 0.2392157  0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.3529412\n",
      " 0.5411765  0.9215687  0.9215687  0.9215687  0.9215687  0.9215687\n",
      " 0.9215687  0.9843138  0.9843138  0.9725491  0.9960785  0.9607844\n",
      " 0.9215687  0.74509805 0.08235294 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.54901963 0.9843138  0.9960785  0.9960785\n",
      " 0.9960785  0.9960785  0.9960785  0.9960785  0.9960785  0.9960785\n",
      " 0.9960785  0.9960785  0.9960785  0.9960785  0.9960785  0.9960785\n",
      " 0.7411765  0.09019608 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.8862746  0.9960785  0.81568635 0.7803922  0.7803922  0.7803922\n",
      " 0.7803922  0.54509807 0.2392157  0.2392157  0.2392157  0.2392157\n",
      " 0.2392157  0.5019608  0.8705883  0.9960785  0.9960785  0.7411765\n",
      " 0.08235294 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.14901961 0.32156864\n",
      " 0.0509804  0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.13333334 0.8352942  0.9960785  0.9960785  0.45098042 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.32941177\n",
      " 0.9960785  0.9960785  0.9176471  0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.32941177 0.9960785  0.9960785\n",
      " 0.9176471  0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.4156863  0.6156863  0.9960785  0.9960785  0.95294124 0.20000002\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.09803922\n",
      " 0.45882356 0.8941177  0.8941177  0.8941177  0.9921569  0.9960785\n",
      " 0.9960785  0.9960785  0.9960785  0.94117653 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.26666668 0.4666667  0.86274517 0.9960785  0.9960785\n",
      " 0.9960785  0.9960785  0.9960785  0.9960785  0.9960785  0.9960785\n",
      " 0.9960785  0.5568628  0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.14509805 0.73333335 0.9921569\n",
      " 0.9960785  0.9960785  0.9960785  0.8745099  0.8078432  0.8078432\n",
      " 0.29411766 0.26666668 0.8431373  0.9960785  0.9960785  0.45882356\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.4431373  0.8588236  0.9960785  0.9490197  0.89019614 0.45098042\n",
      " 0.34901962 0.12156864 0.         0.         0.         0.\n",
      " 0.7843138  0.9960785  0.9450981  0.16078432 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.6627451  0.9960785\n",
      " 0.6901961  0.24313727 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.18823531 0.9058824  0.9960785\n",
      " 0.9176471  0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.07058824 0.48627454 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.32941177 0.9960785  0.9960785  0.6509804  0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.54509807\n",
      " 0.9960785  0.9333334  0.22352943 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.8235295  0.9803922  0.9960785  0.65882355\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.9490197  0.9960785  0.93725497 0.22352943 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.34901962 0.9843138  0.9450981\n",
      " 0.3372549  0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.01960784 0.8078432  0.96470594 0.6156863  0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.01568628 0.45882356\n",
      " 0.27058825 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.        ]\n",
      "Example training data label:  [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# 查看某张图片像素矩阵生成的的一维数组及其相应的标签\n",
    "print(\"Example training data: \", mnist.train.images[0])\n",
    "print(\"Example training data label: \", mnist.train.labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mnist.train.next_batch函数可以从所有训练数据中读取一小部分作为一个训练batch。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (100, 784)\n",
      "Y shape: (100, 10)\n"
     ]
    }
   ],
   "source": [
    "# 使用mnist.train.next_batch函数\n",
    "batch_size = 100\n",
    "xs, ys = mnist.train.next_batch(batch_size)\n",
    "# 从train的集合中选取batch_size个训练数据。\n",
    "print(\"X shape:\", xs.shape)\n",
    "print(\"Y shape:\", ys.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 神经网络模型训练及不同模型结果对比"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面给出完整的TensorFlow程序解决MNIST手写体数字识别问题，用到了带指数衰减的学习率设置、正则化避免过拟合、滑动平均模型使模型更健壮。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 设置输入和输出节点的个数，配置神经网络的参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "#MNIST数据集相关的常数\n",
    "INPUT_NODE = 784     # 输入节点，等于图片的像素\n",
    "OUTPUT_NODE = 10     # 输出节点，等于类别的数目\n",
    "\n",
    "#配置神经网络的参数\n",
    "LAYER1_NODE = 500    # 隐藏层结点数，这里使用只有一个隐藏层的网络结构作为样例\n",
    "BATCH_SIZE = 100     # 一个训练batch中的的样本个数。\n",
    "                     # 数字越小越接近随机梯度下降，越大越接近梯度下降\n",
    "LEARNING_RATE_BASE = 0.8    # 基础的学习率\n",
    "LEARNING_RATE_DECAY = 0.99    # 学习率的衰减率\n",
    "REGULARAZTION_RATE = 0.0001   # 描述模型复杂度的正则化项在损失函数中的系数\n",
    "TRAINING_STEPS = 30000        # 训练轮数\n",
    "MOVING_AVERAGE_DECAY = 0.99  # 滑动平均衰减率    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 定义辅助函数来计算前向传播结果，定义使用ReLU做为激活函数的三层全连接神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(input_tensor, avg_class, \n",
    "              weights1, biases1, \n",
    "              weights2, biases2):\n",
    "    # 当没有提供滑动平均类时，直接使用参数当前的取值\n",
    "    if avg_class == None:\n",
    "        # 计算隐藏层的前向传播结果\n",
    "        layer1 = tf.nn.relu(tf.matmul(input_tensor, weights1) + biases1)\n",
    "        # 因为在计算损失函数时会一并计算softmax函数，所以这里不需要加入\n",
    "        # 因为预测是使用的是输出值相对大小，所以softmax层也可以不加入\n",
    "        return tf.matmul(layer1, weights2) + biases2\n",
    "    \n",
    "    else:\n",
    "        # 使用avg_class.average函数来计算得出变量的滑动平均值\n",
    "        # 然后计算相应的神经网络前向传播结果\n",
    "        layer1 = tf.nn.relu(tf.matmul(input_tensor, avg_class.average(weights1)) + \n",
    "                            avg_class.average(biases1))\n",
    "        return tf.matmul(layer1, avg_class.average(weights2)) + avg_class.average(biases2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 训练模型的过程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(mnist):\n",
    "    x = tf.placeholder(tf.float32, [None, INPUT_NODE], name='x-input')\n",
    "    y_ = tf.placeholder(tf.float32, [None, OUTPUT_NODE], name='y-input')\n",
    "    \n",
    "    # 生成隐藏层的参数。\n",
    "    weights1 = tf.Variable(\n",
    "        tf.truncated_normal([INPUT_NODE, LAYER1_NODE], stddev=0.1))\n",
    "    biases1 = tf.Variable(tf.constant(0.1, shape=[LAYER1_NODE]))\n",
    "    # 生成输出层的参数。\n",
    "    weights2 = tf.Variable(\n",
    "        tf.truncated_normal([LAYER1_NODE, OUTPUT_NODE], stddev=0.1))\n",
    "    biases2 = tf.Variable(tf.constant(0.1, shape=[OUTPUT_NODE]))\n",
    "    \n",
    "    # 计算不含滑动平均类的前向传播结果\n",
    "    y = inference(x, None, weights1, biases1, weights2, biases2)\n",
    "    \n",
    "    # 定义存储训练轮数的变量\n",
    "    # 这个变量不需要计算滑动平均值，所以指定为不可训练的比俺俩\n",
    "    # 在使用TF训练神经网络时，一般会将代表训练轮数的变量指定为不可训练的参数\n",
    "    global_step = tf.Variable(0, trainable=False)\n",
    "    \n",
    "    # 给定滑动平均衰减率和训练轮数的变量，初始化滑动平均类\n",
    "    variable_averages = tf.train.ExponentialMovingAverage(\n",
    "        MOVING_AVERAGE_DECAY, global_step)\n",
    "    \n",
    "    # 在所有代表神经网络参数的变量上使用滑动平均\n",
    "    # tf.trainable_variables返回的是图上集合GraphKeys.TRAINABLE_VARIABLES中的元素，这个集合的元素\n",
    "    # 就是所有没有指定trainable=Flase的参数\n",
    "    variables_averages_op = variable_averages.apply(\n",
    "        tf.trainable_variables())\n",
    "    \n",
    "    # 计算使用了滑动平均之后的前向传播结果\n",
    "    average_y = inference(\n",
    "        x, variable_averages, weights1, biases1, weights2, biases2)\n",
    "    \n",
    "    # 计算交叉熵及其平均值\n",
    "    # tf.argmax函数得到正确答案对应的类别编号\n",
    "    cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "        logits=y, labels=tf.argmax(y_, 1))\n",
    "    #计算当前batch中所有样例的交叉熵平均值\n",
    "    cross_entropy_mean = tf.reduce_mean(cross_entropy)\n",
    "    \n",
    "    # L2正则化损失函数的计算\n",
    "    regularizer = tf.contrib.layers.l2_regularizer(REGULARAZTION_RATE)\n",
    "    # 计算模型的正则化损失，一般只计算神经网络边上权重的正则化损失，而不使用偏置项\n",
    "    regularization = regularizer(weights1) + regularizer(weights2)\n",
    "    # 总损失等于交叉熵损失和正则化损失之和\n",
    "    loss = cross_entropy_mean + regularization\n",
    "    # 设置指数衰减的学习率。\n",
    "    learning_rate = tf.train.exponential_decay(\n",
    "        LEARNING_RATE_BASE, # 基础的学习率\n",
    "        global_step, # 当前迭代的轮数\n",
    "        mnist.train.num_examples / BATCH_SIZE, # 过完所有训练数据需要的迭代次数 \n",
    "        LEARNING_RATE_DECAY, # 学习率衰减速度\n",
    "        staircase=True)\n",
    "    \n",
    "    # 优化损失函数\n",
    "    train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, global_step=global_step)\n",
    "    \n",
    "    # 反向传播更新参数和更新每一个参数的滑动平均值\n",
    "    # tf支持进行一次完成多个操作,提供了tf.control_dependencies和tf.group两种机制\n",
    "    # 例如创建一个group，把train_step和variables_averages_op两个操作放在一起进行，等同于以下操作：\n",
    "    # with tf.control_dependencies([train_step, variables_averages_op]):\n",
    "    #     train_op = tf.no_op(name='train')\n",
    "    train_op = tf.group(train_step, variables_averages_op)    \n",
    "    \n",
    "    # 计算正确率\n",
    "    # average_y.shape = [None, OUTPUT_NODE]，tf.argmax(average_y, 1)表示返回average_y中最大值的序号\n",
    "    # Signature: tf.argmax(input, axis=None, name=None, dimension=None, output_type=tf.int64)\n",
    "    # Returns the index with the largest value across axes of a tensor. (deprecated arguments)\n",
    "    correct_prediction = tf.equal(tf.argmax(average_y, 1), tf.argmax(y_, 1))\n",
    "    # 将布尔型数值转换为实数型，然后计算平均值。这个平均值就是模型在这一组数据上的正确率\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    \n",
    "    # 初始化会话并开始训练过程。\n",
    "    with tf.Session() as sess:\n",
    "        tf.global_variables_initializer().run()\n",
    "        # 准备验证数据\n",
    "        validate_feed = {x: mnist.validation.images, \n",
    "                         y_: mnist.validation.labels}\n",
    "        # 准备测试数据。在真实应用中，这部分数据在测试时是不可见的，这个数据只是作为模型优劣的最后评价标准\n",
    "        test_feed = {x: mnist.test.images, y_: mnist.test.labels} \n",
    "        \n",
    "        # 迭代地训练神经网络。\n",
    "        for i in range(TRAINING_STEPS):\n",
    "            # 每1000轮输出一次在验证数据集上的测试结果\n",
    "            if i % 1000 == 0:\n",
    "                # 计算滑动平均模型在验证数据上的结果\n",
    "                # 因为MNIST数据集比较小，所以一次可以处理所有的验证数据，而不需要划分更小的batch\n",
    "                validate_acc = sess.run(accuracy, feed_dict=validate_feed)\n",
    "                print(\"After %d training step(s), validation accuracy \"\n",
    "                      \"using average model is %g \" % (i, validate_acc))\n",
    "                \n",
    "            # 产生这一轮使用的一个batch的训练数据，并运行训练过程\n",
    "            xs, ys = mnist.train.next_batch(BATCH_SIZE)\n",
    "            sess.run(train_op, feed_dict={x:xs,y_:ys})\n",
    "            \n",
    "        # 在训练结束之后，在测试数据上检测神经网络模型的最终正确率\n",
    "        test_acc=sess.run(accuracy,feed_dict=test_feed)\n",
    "        print(\"After %d training step(s), test accuracy using average \"\n",
    "              \"model is %g\" %(TRAINING_STEPS, test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. 主程序入口"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data\\train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data\\train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data\\t10k-labels-idx1-ubyte.gz\n",
      "After 0 training step(s), validation accuracy using average model is 0.1246 \n",
      "After 1000 training step(s), validation accuracy using average model is 0.976 \n",
      "After 2000 training step(s), validation accuracy using average model is 0.9822 \n",
      "After 3000 training step(s), validation accuracy using average model is 0.9824 \n",
      "After 4000 training step(s), validation accuracy using average model is 0.9832 \n",
      "After 5000 training step(s), validation accuracy using average model is 0.9832 \n",
      "After 6000 training step(s), validation accuracy using average model is 0.9842 \n",
      "After 7000 training step(s), validation accuracy using average model is 0.984 \n",
      "After 8000 training step(s), validation accuracy using average model is 0.9832 \n",
      "After 9000 training step(s), validation accuracy using average model is 0.9844 \n",
      "After 10000 training step(s), validation accuracy using average model is 0.984 \n",
      "After 11000 training step(s), validation accuracy using average model is 0.9844 \n",
      "After 12000 training step(s), validation accuracy using average model is 0.9836 \n",
      "After 13000 training step(s), validation accuracy using average model is 0.9846 \n",
      "After 14000 training step(s), validation accuracy using average model is 0.985 \n",
      "After 15000 training step(s), validation accuracy using average model is 0.9852 \n",
      "After 16000 training step(s), validation accuracy using average model is 0.9852 \n",
      "After 17000 training step(s), validation accuracy using average model is 0.9852 \n",
      "After 18000 training step(s), validation accuracy using average model is 0.9848 \n",
      "After 19000 training step(s), validation accuracy using average model is 0.9856 \n",
      "After 20000 training step(s), validation accuracy using average model is 0.9846 \n",
      "After 21000 training step(s), validation accuracy using average model is 0.9844 \n",
      "After 22000 training step(s), validation accuracy using average model is 0.9844 \n",
      "After 23000 training step(s), validation accuracy using average model is 0.985 \n",
      "After 24000 training step(s), validation accuracy using average model is 0.985 \n",
      "After 25000 training step(s), validation accuracy using average model is 0.9844 \n",
      "After 26000 training step(s), validation accuracy using average model is 0.986 \n",
      "After 27000 training step(s), validation accuracy using average model is 0.9854 \n",
      "After 28000 training step(s), validation accuracy using average model is 0.9854 \n",
      "After 29000 training step(s), validation accuracy using average model is 0.9854 \n",
      "After 30000 training step(s), test accuracy using average model is 0.9832\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\74575\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2969: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "def main(argv=None):\n",
    "    # 声明处理MNIST数据集的类，这个类在初始化时会自动下载数据\n",
    "    mnist = input_data.read_data_sets(\"/tmp/data\", one_hot=True)\n",
    "    train(mnist)\n",
    "\n",
    "# TensorFlow提供的一个主程序入口，tf.app.run会调用上面定义的main函数\n",
    "if __name__=='__main__':\n",
    "    tf.app.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从结果看出，从4000轮开始，模型在验证数据集上的表现开始波动，说明模型已经接近极小值，迭代也可以结束了。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "除了使用验证数据集，还可以采用交叉验证（cross validation），但因为神经网络训练时间本身就比较长，采用cross validation会花费大量时间，所以在海量数据的情况下，一般会更多地采用验证数据集的形式来评测模型的效果。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在这里，一个模型在MNIST测试数据集上的正确率将简称为“正确率”。  \n",
    "前面提到了设计神经网络时的5种优化方法：  \n",
    "在神经网络结构的设计上，需要使用激活函数和多层隐藏层；  \n",
    "在神经网络优化时，可以使用指数衰减的学习率、加入正则化的损失函数、滑动平均模型。  \n",
    "使用所有优化、不用滑动平均、不用正则化、不用指数衰减学习率、不用隐藏层、不用激活函数（学习率改为0.05）的正确率分别为：  \n",
    "0.9841、0.9839、0.9831、0.9838、0.9256、0.9257（10次运行的平均值）  \n",
    "可以发现神经网络的结构对最终模型的效果有本质性的影响。  \n",
    "当问题更加复杂时，滑动平均模型和指数衰减的学习率可以发挥更大作用：例如在CIFAR-10图像分类数据集上，使用滑动平均模型可以将错误率降低11%，使用指数衰减的学习率可以将错误率降低7%。  \n",
    "加入正则化的损失函数给模型效果带来的提升要相对显著。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由于MNIST问题本身相对简单，优化方法提升效果不明显，但当需要解决的问题和模型更加复杂时，这些优化方法将产生更大影响。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
